{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"iQdsYn8KgE4T","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#1-Import du dataset depuis le drive","metadata":{"id":"zTh6hOzHhWe6"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"O-2UWz6tgmXb","outputId":"1dd733a3-a8e4-43b4-ceed-255f2d8ecb56","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:02.184754Z","iopub.execute_input":"2025-04-14T18:22:02.185026Z","iopub.status.idle":"2025-04-14T18:22:02.188434Z","shell.execute_reply.started":"2025-04-14T18:22:02.185006Z","shell.execute_reply":"2025-04-14T18:22:02.187818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","metadata":{"id":"GSOLMY6bgpa9","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:02.189563Z","iopub.execute_input":"2025-04-14T18:22:02.190078Z","iopub.status.idle":"2025-04-14T18:22:03.272401Z","shell.execute_reply.started":"2025-04-14T18:22:02.190059Z","shell.execute_reply":"2025-04-14T18:22:03.271827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train=\"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\ntest=\"/kaggle/input/new-plant-diseases-dataset/test\"\nvalid=\"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"","metadata":{"id":"KsFapk27hFVK","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:03.273738Z","iopub.execute_input":"2025-04-14T18:22:03.274127Z","iopub.status.idle":"2025-04-14T18:22:03.277907Z","shell.execute_reply.started":"2025-04-14T18:22:03.274083Z","shell.execute_reply":"2025-04-14T18:22:03.277198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_file_name=os.listdir(train)\ntest_file_name=os.listdir(test)\nvalid_file_name=os.listdir(valid)","metadata":{"id":"RF185XOshGKN","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:03.278560Z","iopub.execute_input":"2025-04-14T18:22:03.278741Z","iopub.status.idle":"2025-04-14T18:22:03.365996Z","shell.execute_reply.started":"2025-04-14T18:22:03.278726Z","shell.execute_reply":"2025-04-14T18:22:03.364991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_file_name","metadata":{"id":"-Rw-VS8WkgOx","outputId":"c3b7ce43-ffea-41d2-9960-7fcd1eb1ac9b","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:03.368329Z","iopub.execute_input":"2025-04-14T18:22:03.369075Z","iopub.status.idle":"2025-04-14T18:22:03.376113Z","shell.execute_reply.started":"2025-04-14T18:22:03.369041Z","shell.execute_reply":"2025-04-14T18:22:03.375154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## preprocessing des Images d'entrainements","metadata":{"id":"JiD37PiO3WpR"}},{"cell_type":"code","source":"#train set\nimport tensorflow as tf\ntraining_set = tf.keras.utils.image_dataset_from_directory(\n    train,                           # Chemin vers le dossier racine contenant les sous-dossiers d'images pour la validation.\n    labels=\"inferred\",               # Les étiquettes (labels) sont déduites automatiquement à partir des noms des sous-dossiers.\n    label_mode=\"categorical\",        # Les labels sont encodés en vecteurs \"one-hot\" (catégoriel).\n    class_names=None,                # Si None, les noms des classes sont déduits par ordre alphabétique à partir des sous-dossiers.\n    color_mode=\"rgb\",                # Les images sont chargées en mode couleur (3 canaux : rouge, vert, bleu).\n    batch_size=32,                   # Nombre d'images par lot (batch). Ici, chaque batch contiendra 32 images.\n    image_size=(128, 128),           # Redimensionnement de chaque image à la taille 128x128 pixels.\n    shuffle=True,                    # Mélange les images dans le dataset pour une meilleure distribution lors de l'entraînement.\n    seed=None,                       # La graine aléatoire utilisée pour le mélange; ici non spécifiée.\n    validation_split=None,           # Aucun fractionnement du dataset (la totalité des images du dossier est utilisée).\n    subset=None,                     # Puisque validation_split est None, il n'y a pas de sous-ensemble (\"training\" ou \"validation\") défini.\n    interpolation=\"bilinear\",        # Méthode d'interpolation utilisée lors du redimensionnement des images (ici, bilinéaire).\n    follow_links=False,              # Ne pas suivre les liens symboliques dans le répertoire.\n    crop_to_aspect_ratio=False       # Ne pas recadrer l'image pour conserver le rapport hauteur/largeur initial.\n)","metadata":{"id":"Xd14abav3EH1","outputId":"d6ef68b1-ef39-4b93-ad33-8016ba291983","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:22:03.376965Z","iopub.execute_input":"2025-04-14T18:22:03.377234Z","iopub.status.idle":"2025-04-14T18:23:21.888870Z","shell.execute_reply.started":"2025-04-14T18:22:03.377207Z","shell.execute_reply":"2025-04-14T18:23:21.888283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Création du jeu de données de validation à partir d'un dossier d'images\nvalidation_set = tf.keras.utils.image_dataset_from_directory(\n    valid,                           # Chemin vers le dossier racine contenant les sous-dossiers d'images pour la validation.\n    labels=\"inferred\",               # Les étiquettes (labels) sont déduites automatiquement à partir des noms des sous-dossiers.\n    label_mode=\"categorical\",        # Les labels sont encodés en vecteurs \"one-hot\" (catégoriel).\n    class_names=None,                # Si None, les noms des classes sont déduits par ordre alphabétique à partir des sous-dossiers.\n    color_mode=\"rgb\",                # Les images sont chargées en mode couleur (3 canaux : rouge, vert, bleu).\n    batch_size=32,                   # Nombre d'images par lot (batch). Ici, chaque batch contiendra 32 images.\n    image_size=(128, 128),           # Redimensionnement de chaque image à la taille 128x128 pixels.\n    shuffle=True,                    # Mélange les images dans le dataset pour une meilleure distribution lors de l'entraînement.\n    seed=None,                       # La graine aléatoire utilisée pour le mélange; ici non spécifiée.\n    validation_split=None,           # Aucun fractionnement du dataset (la totalité des images du dossier est utilisée).\n    subset=None,                     # Puisque validation_split est None, il n'y a pas de sous-ensemble (\"training\" ou \"validation\") défini.\n    interpolation=\"bilinear\",        # Méthode d'interpolation utilisée lors du redimensionnement des images (ici, bilinéaire).\n    follow_links=False,              # Ne pas suivre les liens symboliques dans le répertoire.\n    crop_to_aspect_ratio=False       # Ne pas recadrer l'image pour conserver le rapport hauteur/largeur initial.\n)\n","metadata":{"id":"mliyefxZ3sVm","outputId":"4caa70f1-e99d-402a-bbca-364c6538c4e7","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:21.889707Z","iopub.execute_input":"2025-04-14T18:23:21.889954Z","iopub.status.idle":"2025-04-14T18:23:26.216530Z","shell.execute_reply.started":"2025-04-14T18:23:21.889934Z","shell.execute_reply":"2025-04-14T18:23:26.215949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Afficher les classes (noms des dossiers)\nprint(\"Classes:\", training_set.class_names)","metadata":{"id":"ypO_eAaK306x","outputId":"0d422766-c0d3-4c96-b2b5-0260379c0ea3","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:26.217258Z","iopub.execute_input":"2025-04-14T18:23:26.217466Z","iopub.status.idle":"2025-04-14T18:23:26.221711Z","shell.execute_reply.started":"2025-04-14T18:23:26.217449Z","shell.execute_reply":"2025-04-14T18:23:26.220977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parcourir quelques batches du dataset\nfor images, labels in training_set.take(1):  # ici on prend un batch, à ajuster si nécessaire\n    batch_size = images.shape[0]\n\n    # Définir la taille de la figure en fonction du nombre d'images à afficher\n    plt.figure(figsize=(5, 5))\n\n    # Pour chaque image du batch, afficher l'image et le nom de la classe correspondante\n    for i in range(batch_size-20):\n        # Calculer l'indice de la classe à partir du vecteur one-hot\n        label_index = labels[i].numpy().argmax()\n        # Récupérer le nom de la classe à partir de training_set.class_names\n        label_name = training_set.class_names[label_index]\n\n        # Afficher l'image dans un subplot\n        # ax = plt.subplot(6, 6, i + 1)  # Ajustez la grille selon batch_size\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(label_name)\n        plt.axis(\"off\")\n        plt.show()\n","metadata":{"id":"6X0rjHxG6flt","outputId":"98819aba-7392-40fc-a84d-3120aad8acb3","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:26.222519Z","iopub.execute_input":"2025-04-14T18:23:26.222774Z","iopub.status.idle":"2025-04-14T18:23:28.259225Z","shell.execute_reply.started":"2025-04-14T18:23:26.222754Z","shell.execute_reply":"2025-04-14T18:23:28.258412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_set.class_names[9]","metadata":{"id":"tsjVWMfc5dld","outputId":"ff236007-8e41-416d-aea1-42a00cfa93ec","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:28.259958Z","iopub.execute_input":"2025-04-14T18:23:28.260283Z","iopub.status.idle":"2025-04-14T18:23:28.265037Z","shell.execute_reply.started":"2025-04-14T18:23:28.260260Z","shell.execute_reply":"2025-04-14T18:23:28.264455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Entrainement du modele","metadata":{"id":"4m1TygoN7xYJ"}},{"cell_type":"code","source":"cnn = tf.keras.models.Sequential()\n\ncnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\ncnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\ncnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\ncnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\ncnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\ncnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\ncnn.add(tf.keras.layers.Dropout(0.25))\ncnn.add(tf.keras.layers.Flatten())\ncnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))\ncnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting\n#Output Layer\ncnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))","metadata":{"id":"R5wqbZd39QAD","outputId":"df9bef16-ffea-4359-e2aa-b3cb79e00de6","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:28.267125Z","iopub.execute_input":"2025-04-14T18:23:28.267336Z","iopub.status.idle":"2025-04-14T18:23:29.232322Z","shell.execute_reply.started":"2025-04-14T18:23:28.267321Z","shell.execute_reply":"2025-04-14T18:23:29.231720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n            loss='categorical_crossentropy',\n            metrics=['accuracy'])\n# Callbacks\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n#     tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n# ]","metadata":{"id":"yKc5vPty-YK8","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:29.232999Z","iopub.execute_input":"2025-04-14T18:23:29.233217Z","iopub.status.idle":"2025-04-14T18:23:29.244819Z","shell.execute_reply.started":"2025-04-14T18:23:29.233202Z","shell.execute_reply":"2025-04-14T18:23:29.244136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn.summary()","metadata":{"id":"QN7lHsQH-uZl","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:29.245653Z","iopub.execute_input":"2025-04-14T18:23:29.245886Z","iopub.status.idle":"2025-04-14T18:23:29.279062Z","shell.execute_reply.started":"2025-04-14T18:23:29.245869Z","shell.execute_reply":"2025-04-14T18:23:29.278529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)","metadata":{"id":"7d2yqAVV-4c0","outputId":"8d4eec0a-641d-49c2-de45-1f0f0e252668","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:23:29.279724Z","iopub.execute_input":"2025-04-14T18:23:29.279944Z","iopub.status.idle":"2025-04-14T18:38:04.294906Z","shell.execute_reply.started":"2025-04-14T18:23:29.279927Z","shell.execute_reply":"2025-04-14T18:38:04.294210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n# 2. Sauvegarde du modèle\njoblib.dump(cnn, 'plantdeases.joblib')","metadata":{"id":"IRS4GkcHfEdH","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:38:04.295998Z","iopub.execute_input":"2025-04-14T18:38:04.296256Z","iopub.status.idle":"2025-04-14T18:38:04.838056Z","shell.execute_reply.started":"2025-04-14T18:38:04.296239Z","shell.execute_reply":"2025-04-14T18:38:04.837418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sauvegarde du modèle\ncnn.save('plantdeases_final.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T18:38:04.838887Z","iopub.execute_input":"2025-04-14T18:38:04.839159Z","iopub.status.idle":"2025-04-14T18:38:05.044786Z","shell.execute_reply.started":"2025-04-14T18:38:04.839132Z","shell.execute_reply":"2025-04-14T18:38:05.044235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation du modele","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Training set Accuracy\ntrain_loss, train_acc = cnn.evaluate(training_set)\nprint('Training accuracy:', train_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:00:05.760803Z","iopub.execute_input":"2025-04-14T19:00:05.761413Z","iopub.status.idle":"2025-04-14T19:00:42.010856Z","shell.execute_reply.started":"2025-04-14T19:00:05.761390Z","shell.execute_reply":"2025-04-14T19:00:42.010074Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.9833 - loss: 0.0494\nTraining accuracy: 0.9852905869483948\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#Validation set Accuracy\nval_loss, val_acc = cnn.evaluate(validation_set)\nprint('Validation accuracy:', val_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = [i for i in range(1,11)]\nplt.plot(epochs,training_history.history['accuracy'],color='red',label='Training Accuracy')\nplt.plot(epochs,training_history.history['val_accuracy'],color='blue',label='Validation Accuracy')\nplt.xlabel('No. of Epochs')\nplt.title('Visualization of Accuracy Result')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}